{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "organ_1st = 'leaf'\n",
    "organ_2nd = 'entire'\n",
    "top_k = 50\n",
    "nb_class = 50\n",
    "flag_preprocess = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (flag_preprocess):\n",
    "    f_1st = open('./fusion_data/' + 'single_organ_score/test_result_50_' + organ_1st + '_pretrained.txt', 'r')\n",
    "    f_2nd = open('./fusion_data/' + 'single_organ_score/test_result_50_' + organ_2nd + '_pretrained.txt', 'r')\n",
    "    fo_1st = open('./fusion_data/' + organ_1st + '_' + organ_2nd + '_50_species/test_result_50_' + organ_1st + '_pretrained.txt', 'w')\n",
    "    fo_2nd = open('./fusion_data/' + organ_1st + '_' + organ_2nd + '_50_species/test_result_50_' + organ_2nd + '_pretrained.txt', 'w')\n",
    "\n",
    "    count_line = 0\n",
    "    for line_1st in f_1st:\n",
    "        fo_1st.write(str(count_line/nb_class) + ' ' + line_1st.split(' ')[-3] +\n",
    "                      ' ' + line_1st.split(' ')[-2] +  ' ' + line_1st.split(' ')[-1])\n",
    "        count_line = count_line + 1\n",
    "    count_line = 0    \n",
    "    for line_2nd in f_2nd:\n",
    "        fo_2nd.write(str(count_line/nb_class) + ' ' + line_2nd.split(' ')[-3] +\n",
    "                      ' ' + line_2nd.split(' ')[-2] + ' ' + line_2nd.split(' ')[-1])\n",
    "        count_line = count_line + 1\n",
    "\n",
    "    f_1st.close()\n",
    "    f_2nd.close()\n",
    "    fo_1st.close()\n",
    "    fo_2nd.close()\n",
    "\n",
    "    f_1st = open('./fusion_data/' + 'single_organ_score/svm_result_50_' + organ_1st + '_pretrained.txt', 'r')\n",
    "    f_2nd = open('./fusion_data/' + 'single_organ_score/svm_result_50_' + organ_2nd + '_pretrained.txt', 'r')\n",
    "    fo_1st = open('./fusion_data/' + organ_1st + '_' + organ_2nd + '_50_species/svm_result_50_' + organ_1st + '_pretrained.txt', 'w')\n",
    "    fo_2nd = open('./fusion_data/' + organ_1st + '_' + organ_2nd + '_50_species/svm_result_50_' + organ_2nd + '_pretrained.txt', 'w')\n",
    "\n",
    "    count_line = 0   \n",
    "    for line_1st in f_1st:\n",
    "        fo_1st.write(str(count_line/nb_class) + ' ' + line_1st.split(' ')[-3] +\n",
    "                      ' ' + line_1st.split(' ')[-2] +  ' ' + line_1st.split(' ')[-1])\n",
    "        count_line = count_line + 1\n",
    "    count_line = 0    \n",
    "    for line_2nd in f_2nd:\n",
    "        fo_2nd.write(str(count_line/nb_class) + ' ' + line_2nd.split(' ')[-3] +\n",
    "                      ' ' + line_2nd.split(' ')[-2] + ' ' + line_2nd.split(' ')[-1])\n",
    "        count_line = count_line + 1\n",
    "\n",
    "    f_1st.close()\n",
    "    f_2nd.close()\n",
    "    fo_1st.close()\n",
    "    fo_2nd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum, Product, Max rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_class = 50\n",
    "\n",
    "f_1st = open('./fusion_data/' 'single_organ_score/test_result_50_' + organ_1st + '_pretrained.txt', 'r')\n",
    "f_2nd = open('./fusion_data/' 'single_organ_score/test_result_50_' + organ_2nd + '_pretrained.txt', 'r')\n",
    "\n",
    "score_1st = list()\n",
    "score_2nd = list()\n",
    "labels = list()\n",
    "\n",
    "for line in f_1st:\n",
    "    score_1st.append(float(line.split(' ')[-1]))\n",
    "    labels.append(int(line.split(' ')[-3]))\n",
    "    \n",
    "for line in f_2nd:\n",
    "    score_2nd.append(float(line.split(' ')[-1]))\n",
    "    \n",
    "st = list()\n",
    "nd = list()\n",
    "max_fu = list()\n",
    "sum_fu = list()\n",
    "prod_fu = list()\n",
    "\n",
    "max_fusion =  np.maximum(np.array(score_1st) , np.array(score_2nd))\n",
    "sum_fusion =  np.array(score_1st) + np.array(score_2nd)\n",
    "prod_fusion =  np.array(score_1st) * np.array(score_2nd)\n",
    "\n",
    "for k in range(1, top_k):\n",
    "    count_true_max = 0\n",
    "    count_true_sum = 0\n",
    "    count_true_prod = 0\n",
    "    count_true_1st = 0\n",
    "    count_true_2nd = 0\n",
    "    \n",
    "    for i in range(len(score_1st)/nb_class):\n",
    "        if labels[i * nb_class] in np.argsort(max_fusion[i * nb_class : (i + 1) * nb_class])[-k:]:\n",
    "            count_true_max = count_true_max + 1\n",
    "        \n",
    "        if labels[i * nb_class] in np.argsort(sum_fusion[i * nb_class : (i + 1) * nb_class])[-k:]:\n",
    "            count_true_sum = count_true_sum + 1\n",
    "            \n",
    "        if labels[i * nb_class] in np.argsort(prod_fusion[i * nb_class : (i + 1) * nb_class])[-k:]:\n",
    "            count_true_prod = count_true_prod + 1\n",
    "            \n",
    "        if labels[i * nb_class] in np.argsort(score_1st[i * nb_class : (i + 1) * nb_class])[-k:]:\n",
    "            count_true_1st = count_true_1st + 1\n",
    "\n",
    "        if labels[i * nb_class] in np.argsort(score_2nd[i * nb_class : (i + 1) * nb_class])[-k:]:\n",
    "            count_true_2nd = count_true_2nd + 1\n",
    "\n",
    "    max_fu.append(float(count_true_max) * nb_class/len(score_1st))\n",
    "    sum_fu.append(float(count_true_sum) * nb_class/len(score_1st))\n",
    "    prod_fu.append(float(count_true_prod) * nb_class/len(score_1st))\n",
    "    st.append(float(count_true_1st) * nb_class/len(score_1st))\n",
    "    nd.append(float(count_true_2nd) * nb_class/len(score_1st))\n",
    "\n",
    "f_1st.close()\n",
    "f_2nd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rh_fu = list()\n",
    "svm = list()\n",
    "for i in range(nb_class):\n",
    "    svm.append(SVC(kernel = 'rbf', degree = 2, probability=True))\n",
    "\n",
    "ret_1st = defaultdict(list)\n",
    "ret_2nd = defaultdict(list)\n",
    "labels = defaultdict(list)\n",
    "points = defaultdict(list)\n",
    "svm_img_labels = dict()\n",
    "\n",
    "f_1st = open('./fusion_data/' + organ_1st + '_' + organ_2nd + '_50_species/svm_result_50_' + organ_1st + '_pretrained.txt', 'r')\n",
    "for line in f_1st:\n",
    "    component = line.split(' ')\n",
    "    if int(component[2]) % nb_class == 0:\n",
    "        svm_img_labels[component[0].split('/')[-1]] = int(component[1])\n",
    "    ret_1st[component[0].split('/')[-1]].append(float(component[3]))\n",
    "f_1st.close()\n",
    "f_2nd = open('./fusion_data/' + organ_1st + '_' + organ_2nd + '_50_species/svm_result_50_' + organ_2nd + '_pretrained.txt', 'r')\n",
    "for line in f_2nd:\n",
    "    component = line.split(' ')\n",
    "    ret_2nd[component[0].split('/')[-1]].append(float(component[3]))\n",
    "f_2nd.close()\n",
    "\n",
    "rand_neg_point = random.randint(1, 10000) \n",
    "\n",
    "\n",
    "for key in ret_1st.keys():\n",
    "    points[svm_img_labels[key]].append([ret_1st[key][svm_img_labels[key]], ret_2nd[key][svm_img_labels[key]]])\n",
    "    labels[svm_img_labels[key]].append(1)\n",
    "    for i in range(10):\n",
    "        rand_neg_point = random.randint(1, 10000) \n",
    "        index = rand_neg_point % nb_class\n",
    "        if (index != svm_img_labels[key]):\n",
    "            \n",
    "            if labels[index].count(0) > labels[index].count(1):\n",
    "                continue\n",
    "            points[index].append([ret_1st[key][index], ret_2nd[key][index]])\n",
    "            labels[index].append(0)\n",
    "        #rand_neg_point = rand_neg_point + 1\n",
    "\n",
    "for i in range(nb_class):\n",
    "    svm[i].fit(points[i], labels[i])\n",
    "\n",
    "ret_1st_test = defaultdict(list)\n",
    "ret_2nd_test = defaultdict(list)\n",
    "test_img_labels = dict()\n",
    "\n",
    "f_1st_test = open('./fusion_data/' + organ_1st + '_' + organ_2nd + '_50_species/test_result_50_' + organ_1st + '_pretrained.txt', 'r')\n",
    "for line in f_1st_test:\n",
    "    component = line.split(' ')\n",
    "    if int(component[2]) % nb_class == 0:\n",
    "        test_img_labels[component[0].split('/')[-1]] = int(component[1])\n",
    "    ret_1st_test[component[0].split('/')[-1]].append(float(component[3]))\n",
    "f_1st_test.close()\n",
    "\n",
    "f_2nd_test = open('./fusion_data/' + organ_1st + '_' + organ_2nd + '_50_species/test_result_50_' + organ_2nd + '_pretrained.txt', 'r')\n",
    "for line in f_2nd_test:\n",
    "    component = line.split(' ')\n",
    "    ret_2nd_test[component[0].split('/')[-1]].append(float(component[3]))\n",
    "f_2nd_test.close()\n",
    "\n",
    "for k in range(1, top_k):\n",
    "    count_true = 0\n",
    "    tot_count = 0\n",
    "    for key in ret_1st_test.keys():\n",
    "        pos_list = list()\n",
    "        neg_list = list()\n",
    "        position = 0\n",
    "        for x, y in zip(ret_1st_test[key], ret_2nd_test[key]):\n",
    "            if len(svm[position].predict_proba([[x, y]])[0]) == 1:\n",
    "                position = position + 1\n",
    "                continue\n",
    "            if (svm[position].predict_proba([[x, y]])[0][1] > 0):\n",
    "                #print(svm[position].predict_proba([[x, y]])[0][1])\n",
    "                pos_list.append([x, y, svm[position].predict_proba([[x, y]])[0][1], position])\n",
    "            else:\n",
    "                neg_list.append([x, y, svm[position].predict_proba([[x, y]])[0][1], position])\n",
    "            position = position + 1\n",
    "\n",
    "        if (pos_list):\n",
    "            tot_count = tot_count + 1\n",
    "            pos_list.sort(key = lambda x: x[0] * x[1] * x[2])\n",
    "            if test_img_labels[key] in np.asarray(pos_list[-k:])[:, 3]:\n",
    "                count_true = count_true + 1               \n",
    "        else:\n",
    "            print('Negative point')\n",
    "            neg_list.sort(key = lambda x: (x[0] * x[1]))\n",
    "            tot_count = tot_count + 1\n",
    "            if (neg_list[-1][3] == test_img_labels[key]):\n",
    "                count_true = count_true + 1\n",
    "                print('Bing go!')\n",
    "    rh_fu.append(float(count_true)/(tot_count))\n",
    "    \n",
    "print('max rule: ' + str(max_fu))\n",
    "print('sum rule: ' + str(sum_fu))\n",
    "print('prod rule: ' + str(prod_fu))\n",
    "print(organ_1st + ': ' + str(st))\n",
    "print(organ_2nd + ': ' + str(nd))\n",
    "print('rh rule: ' + str(rh_fu))\n",
    "\n",
    "output = open('./fusion_data/' + organ_1st + '_' + organ_2nd + '_top_' + str(top_k) + '_scores.txt', 'w')\n",
    "output.write('max rule: ' + str(max_fu) + '\\n')\n",
    "output.write('sum rule: ' + str(sum_fu) + '\\n')\n",
    "output.write('prod rule: ' + str(prod_fu) + '\\n')\n",
    "output.write(organ_1st + ': ' + str(st) + '\\n')\n",
    "output.write(organ_2nd + ': ' + str(nd) + '\\n')\n",
    "output.write('rh rule: ' + str(rh_fu))\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot SVM\n",
    "fig, ax = plt.subplots()\n",
    "id = 9\n",
    "h = 0.001\n",
    "x_min, x_max = -0.1, 1.1\n",
    "y_min, y_max = -0.1, 1.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "titles = 'SVC with polynomial (degree 4) kernel'\n",
    "\n",
    "Z = svm[id].predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "\n",
    "colors = color= ['red' if l == 0 else 'green' for l in labels[id]]\n",
    "plt.scatter(np.asarray(points[id])[:, 0], np.asarray(points[id])[:, 1], color = colors)\n",
    "\n",
    "classes = ['Positive','Negative']\n",
    "class_colours = ['green','red']\n",
    "recs = []\n",
    "for i in range(0,len(class_colours)):\n",
    "    recs.append(mpatches.Rectangle((0,0),1,1,fc=class_colours[i]))\n",
    "plt.legend(recs,classes,loc=4)\n",
    "\n",
    "plt.title('Point density for species %d' %id)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
